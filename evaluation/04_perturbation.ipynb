{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhITXrSAHeo06GrXECjjFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliasNoorzad/XAI_Autonomous-Driving/blob/main/evaluation/04_perturbation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtXEQCuTuGuM",
        "outputId": "a827dd0e-639b-4fe1-b199-a92f3965e3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics==8.4.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZmOalPyuKhG",
        "outputId": "1ca5bf9a-dc4c-4490-ec20-c0bf54bc69a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/XAI_Project/BDD100K_640.zip /content/"
      ],
      "metadata": {
        "id": "89TXIVmnuKtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/XAI_Project/daynight_labels.csv /content/"
      ],
      "metadata": {
        "id": "lViHC5h1uKvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/BDD100K_640.zip -d /content/BDD100K_640"
      ],
      "metadata": {
        "id": "nEgqbPlZuK0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml = \"\"\"\\\n",
        "path: /content/BDD100K_640/yolo_640\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "nc: 5\n",
        "names: [car, truck, bus, person, bike]\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/BDD100K_640/yolo_640/dataset_640.yaml\", \"w\") as f:\n",
        "    f.write(yaml)"
      ],
      "metadata": {
        "id": "4lWHOtAxultv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class BDDDetDrivableDataset(Dataset):\n",
        "    \"\"\"\n",
        "    For preprocessed 640 dataset (yolo_640 + drivable_masks_640):\n",
        "      images: <yolo_root>/<split>/images/<stem>.jpg\n",
        "      labels: <yolo_root>/<split>/labels/<stem>.txt\n",
        "      masks : <mask_root>/<split>/<stem>.png\n",
        "\n",
        "    Returns:\n",
        "      img   : FloatTensor [3, H, W] in [0,1]\n",
        "      labels: FloatTensor [N, 5] where each row is [cls, x, y, w, h] (YOLO normalized)\n",
        "      mask  : FloatTensor [1, H, W] with values 0/1\n",
        "      dn    : LongTensor scalar (0=day, 1=night)  <-- always valid (unlabeled images are filtered out)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        yolo_root: str,\n",
        "        mask_root: str,\n",
        "        split: str,\n",
        "        imgsz: int = 640,\n",
        "        dn_csv_path: str | None = None,\n",
        "    ):\n",
        "        self.yolo_root = Path(yolo_root)\n",
        "        self.mask_root = Path(mask_root)\n",
        "        self.split = split\n",
        "        self.imgsz = int(imgsz)\n",
        "\n",
        "        self.img_dir = self.yolo_root / split / \"images\"\n",
        "        self.lbl_dir = self.yolo_root / split / \"labels\"\n",
        "        self.msk_dir = self.mask_root / split\n",
        "\n",
        "        if not self.img_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing images dir: {self.img_dir}\")\n",
        "        if not self.lbl_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing labels dir: {self.lbl_dir}\")\n",
        "        if not self.msk_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing masks dir:  {self.msk_dir}\")\n",
        "\n",
        "        exts = {\".jpg\", \".jpeg\", \".png\"}\n",
        "        self.img_paths = sorted([p for p in self.img_dir.iterdir() if p.suffix.lower() in exts])\n",
        "        if len(self.img_paths) == 0:\n",
        "            raise FileNotFoundError(f\"No images found in: {self.img_dir}\")\n",
        "\n",
        "        #  day/night mapping from CSV\n",
        "        if dn_csv_path is None:\n",
        "            raise RuntimeError(\"dn_csv_path is required for this dataset (day/night head training).\")\n",
        "\n",
        "        dn_csv_path = Path(dn_csv_path)\n",
        "        if not dn_csv_path.exists():\n",
        "            raise FileNotFoundError(f\"Missing day/night CSV: {dn_csv_path}\")\n",
        "\n",
        "        dn_map = {}\n",
        "        with open(dn_csv_path, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            required = {\"split\", \"image_id\", \"label\"}\n",
        "            if not required.issubset(set(reader.fieldnames or [])):\n",
        "                raise ValueError(f\"dn CSV must have columns {required}, got {reader.fieldnames}\")\n",
        "\n",
        "            for row in reader:\n",
        "                if row[\"split\"] != self.split:\n",
        "                    continue\n",
        "\n",
        "                image_id = row[\"image_id\"].strip()   # stem (no extension)\n",
        "                lab = row[\"label\"].strip().lower()\n",
        "\n",
        "                if lab == \"day\":\n",
        "                    dn = 0\n",
        "                elif lab == \"night\":\n",
        "                    dn = 1\n",
        "                else:\n",
        "                    # if CSV contains anything else, it's a data error\n",
        "                    raise ValueError(f\"Invalid dn label in CSV for {image_id}: {row['label']}\")\n",
        "\n",
        "                dn_map[image_id] = dn\n",
        "\n",
        "        self.dn_map = dn_map\n",
        "\n",
        "        # FILTER OUT UNLABELED IMAGES\n",
        "        before = len(self.img_paths)\n",
        "        self.img_paths = [p for p in self.img_paths if p.stem in self.dn_map]\n",
        "        after = len(self.img_paths)\n",
        "        if after == 0:\n",
        "            raise RuntimeError(f\"No labeled (day/night) images found for split='{self.split}'.\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    @staticmethod\n",
        "    def _read_yolo_labels(label_path: Path) -> torch.Tensor:\n",
        "        if not label_path.exists():\n",
        "            return torch.zeros((0, 5), dtype=torch.float32)\n",
        "\n",
        "        rows = []\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                parts = line.split()\n",
        "                if len(parts) != 5:\n",
        "                    continue\n",
        "                cls, x, y, w, h = parts\n",
        "                rows.append([float(cls), float(x), float(y), float(w), float(h)])\n",
        "\n",
        "        if len(rows) == 0:\n",
        "            return torch.zeros((0, 5), dtype=torch.float32)\n",
        "        return torch.tensor(rows, dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def _pil_to_chw_float(img: Image.Image) -> torch.Tensor:\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0\n",
        "        arr = np.transpose(arr, (2, 0, 1))\n",
        "        return torch.from_numpy(arr)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        img_path = self.img_paths[idx]\n",
        "        stem = img_path.stem\n",
        "\n",
        "        label_path = self.lbl_dir / f\"{stem}.txt\"\n",
        "        mask_path = self.msk_dir / f\"{stem}.png\"\n",
        "\n",
        "        if not mask_path.exists():\n",
        "            raise FileNotFoundError(f\"Missing mask for {stem}: {mask_path}\")\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        labels = self._read_yolo_labels(label_path)\n",
        "\n",
        "        if img.size != (self.imgsz, self.imgsz):\n",
        "            img = img.resize((self.imgsz, self.imgsz), resample=Image.BILINEAR)\n",
        "        if mask.size != (self.imgsz, self.imgsz):\n",
        "            mask = mask.resize((self.imgsz, self.imgsz), resample=Image.NEAREST)\n",
        "\n",
        "        img_t = self._pil_to_chw_float(img)\n",
        "        mask_np = (np.array(mask, dtype=np.uint8) > 0).astype(np.float32)\n",
        "        mask_t = torch.from_numpy(mask_np)[None, :, :]\n",
        "\n",
        "        # dn is ALWAYS valid because we filtered img_paths\n",
        "        dn = torch.tensor(self.dn_map[stem], dtype=torch.long)\n",
        "\n",
        "        return img_t, labels, mask_t, dn"
      ],
      "metadata": {
        "id": "HPO6D-qAulwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels: int, reduction: int = 16):\n",
        "        super().__init__()\n",
        "        hidden = max(channels // reduction, 1)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        # shared MLP (implemented with 1x1 convs)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Conv2d(channels, hidden, kernel_size=1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(hidden, channels, kernel_size=1, bias=False),\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        avg_out = self.mlp(self.avg_pool(x))\n",
        "        max_out = self.mlp(self.max_pool(x))\n",
        "        w = self.sigmoid(avg_out + max_out)  # BxCx1x1\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size: int = 7):\n",
        "        super().__init__()\n",
        "        assert kernel_size in (3, 7)\n",
        "        padding = (kernel_size - 1) // 2\n",
        "\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.last_sa = None  # <--- add this\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        mean_map = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_map, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        m = torch.cat([mean_map, max_map], dim=1)\n",
        "\n",
        "        w = self.sigmoid(self.conv(m))  # Bx1xHxW in [0,1]\n",
        "        self.last_sa = w.detach()\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels: int, reduction: int = 16, spatial_kernel: int = 7):\n",
        "        super().__init__()\n",
        "        self.ca = ChannelAttention(channels, reduction=reduction)\n",
        "        self.sa = SpatialAttention(kernel_size=spatial_kernel)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.ca(x)\n",
        "        x = self.sa(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_i4rsH39vEGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "class YOLOv8DetSemSeg(nn.Module):\n",
        "    \"\"\"\n",
        "    YOLOv8 detection model + tiny semantic seg head.\n",
        "    Captures NECK features by hooking the Detect head INPUT (multi-scale features).\n",
        "    \"\"\"\n",
        "    def __init__(self, yolo_weights: str = \"yolov8n.pt\", use_cbam: bool = False):\n",
        "        super().__init__()\n",
        "        self.yolo = YOLO(yolo_weights).model  # nn.Module\n",
        "        self.use_cbam = use_cbam\n",
        "\n",
        "        self.cbam_backbone = None  # Point 1 (after last backbone block)\n",
        "        self.cbam_neck = None      # Point 2 (once in neck before heads)\n",
        "\n",
        "        self._neck_feats = None\n",
        "\n",
        "        self.sem_head = nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self._register_backbone_hook_point1()\n",
        "        self._register_detect_input_hook()\n",
        "\n",
        "    def _register_backbone_hook_point1(self):\n",
        "        # find first upsample -> previous layer output is your last backbone high-level feature\n",
        "        idx_up = None\n",
        "        for i, m in enumerate(self.yolo.model):\n",
        "            if isinstance(m, nn.Upsample) or \"upsample\" in m.__class__.__name__.lower():\n",
        "                idx_up = i\n",
        "                break\n",
        "        if idx_up is None or idx_up == 0:\n",
        "            raise RuntimeError(\"Could not find neck start (Upsample) to place backbone CBAM.\")\n",
        "\n",
        "        backbone_last = self.yolo.model[idx_up - 1]\n",
        "\n",
        "        if hasattr(self, \"_bb_hook_handle\") and self._bb_hook_handle is not None:\n",
        "            self._bb_hook_handle.remove()\n",
        "\n",
        "        def fwd_hook(module, inputs, output):\n",
        "            if not self.use_cbam:\n",
        "                return None\n",
        "            if self.cbam_backbone is None:\n",
        "                self.cbam_backbone = CBAM(channels=output.shape[1]).to(output.device)\n",
        "            return self.cbam_backbone(output)\n",
        "\n",
        "        self._bb_hook_handle = backbone_last.register_forward_hook(fwd_hook)\n",
        "\n",
        "\n",
        "    def _register_detect_input_hook(self):\n",
        "        if not hasattr(self.yolo, \"model\"):\n",
        "            raise RuntimeError(\"Unexpected Ultralytics model: no .model\")\n",
        "\n",
        "        detect_module = self.yolo.model[-1]\n",
        "        name = detect_module.__class__.__name__.lower()\n",
        "        if \"detect\" not in name:\n",
        "            raise RuntimeError(f\"Last module is not Detect (got {detect_module.__class__.__name__}).\")\n",
        "\n",
        "        # remove previous hook if exists\n",
        "        if hasattr(self, \"_detect_hook_handle\") and self._detect_hook_handle is not None:\n",
        "            self._detect_hook_handle.remove()\n",
        "\n",
        "        def pre_hook(module, inputs):\n",
        "            feats = inputs[0]              # should be list of tensors\n",
        "            feats = list(feats)            # FORCE list\n",
        "\n",
        "            if self.use_cbam:\n",
        "                if self.cbam_neck is None:\n",
        "                    self.cbam_neck = CBAM(feats[-1].shape[1]).to(feats[-1].device)\n",
        "                feats[-1] = self.cbam_neck(feats[-1])\n",
        "\n",
        "            self._neck_feats = feats\n",
        "            return (feats,) if self.use_cbam else None\n",
        "          # return list inside the tuple wrapper\n",
        "\n",
        "\n",
        "        self._detect_hook_handle = detect_module.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _pick_high_res_from_detect_inputs(feats):\n",
        "        # feats: list/tuple of [B,C,H,W]\n",
        "        if not isinstance(feats, (list, tuple)) or len(feats) == 0:\n",
        "            raise RuntimeError(\"Detect input features not captured.\")\n",
        "        return max(feats, key=lambda t: t.shape[-2] * t.shape[-1])  # highest H*W (usually P3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # TRAIN: x is a batch dict -> YOLO returns (det_loss, loss_items)\n",
        "      if isinstance(x, dict):\n",
        "          self._neck_feats = None\n",
        "          imgs = x[\"img\"]\n",
        "          det_loss, det_items = self.yolo(x)\n",
        "\n",
        "          feat = self._pick_high_res_from_detect_inputs(self._neck_feats)\n",
        "          seg_logits = self.sem_head(feat)\n",
        "          seg_logits = F.interpolate(seg_logits, size=imgs.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "          return det_loss, det_items, seg_logits\n",
        "\n",
        "      # INFER: x is an image tensor -> YOLO returns preds\n",
        "      self._neck_feats = None\n",
        "      det_preds = self.yolo(x)\n",
        "\n",
        "      feat = self._pick_high_res_from_detect_inputs(self._neck_feats)\n",
        "      seg_logits = self.sem_head(feat)\n",
        "      seg_logits = F.interpolate(seg_logits, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "      return det_preds, seg_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KrI4x9NvJHi",
        "outputId": "05a1b024-d847-42f6-8098-6edf206e4ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "class YOLOv8DetSemSegDn(nn.Module):\n",
        "    \"\"\"\n",
        "    YOLOv8 detection model + tiny semantic seg head.\n",
        "    Captures NECK features by hooking the Detect head INPUT (multi-scale features).\n",
        "    \"\"\"\n",
        "    def __init__(self, yolo_weights: str = \"yolov8n.pt\", use_cbam: bool = False):\n",
        "        super().__init__()\n",
        "        self.yolo = YOLO(yolo_weights).model  # nn.Module\n",
        "        self.use_cbam = use_cbam\n",
        "\n",
        "        self.cbam_backbone = None  # Point 1 (after last backbone block)\n",
        "        self.cbam_neck = None      # Point 2 (CBAM on ALL neck feature maps)\n",
        "\n",
        "        self._neck_feats = None\n",
        "\n",
        "        self.sem_head = nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self.dn_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),  # [B,C,1,1]\n",
        "            nn.Flatten(1),            # [B,C]\n",
        "            nn.LazyLinear(2)          # [B,2] logits: [day, night]\n",
        "        )\n",
        "\n",
        "        self._register_backbone_hook_point1()\n",
        "        self._register_detect_input_hook()\n",
        "\n",
        "    def _register_backbone_hook_point1(self):\n",
        "        idx_up = None\n",
        "        for i, m in enumerate(self.yolo.model):\n",
        "            if isinstance(m, nn.Upsample) or \"upsample\" in m.__class__.__name__.lower():\n",
        "                idx_up = i\n",
        "                break\n",
        "        if idx_up is None or idx_up == 0:\n",
        "            raise RuntimeError(\"Could not find neck start (Upsample) to place backbone CBAM.\")\n",
        "\n",
        "        backbone_last = self.yolo.model[idx_up - 1]\n",
        "\n",
        "        if hasattr(self, \"_bb_hook_handle\") and self._bb_hook_handle is not None:\n",
        "            self._bb_hook_handle.remove()\n",
        "\n",
        "        def fwd_hook(module, inputs, output):\n",
        "            if not self.use_cbam:\n",
        "                return None\n",
        "            if self.cbam_backbone is None:\n",
        "                self.cbam_backbone = CBAM(channels=output.shape[1]).to(output.device)\n",
        "            return self.cbam_backbone(output)\n",
        "\n",
        "        self._bb_hook_handle = backbone_last.register_forward_hook(fwd_hook)\n",
        "\n",
        "    def _register_detect_input_hook(self):\n",
        "        if not hasattr(self.yolo, \"model\"):\n",
        "            raise RuntimeError(\"Unexpected Ultralytics model: no .model\")\n",
        "\n",
        "        detect_module = self.yolo.model[-1]\n",
        "        name = detect_module.__class__.__name__.lower()\n",
        "        if \"detect\" not in name:\n",
        "            raise RuntimeError(f\"Last module is not Detect (got {detect_module.__class__.__name__}).\")\n",
        "\n",
        "        if hasattr(self, \"_detect_hook_handle\") and self._detect_hook_handle is not None:\n",
        "            self._detect_hook_handle.remove()\n",
        "\n",
        "        def pre_hook(module, inputs):\n",
        "            feats = list(inputs[0])  # list of multiscale neck features\n",
        "\n",
        "            if self.use_cbam:\n",
        "                # one CBAM per scale\n",
        "                if self.cbam_neck is None:\n",
        "                    self.cbam_neck = nn.ModuleList([CBAM(f.shape[1]).to(f.device) for f in feats])\n",
        "                # apply to ALL scales\n",
        "                feats = [m(f) for m, f in zip(self.cbam_neck, feats)]\n",
        "\n",
        "            self._neck_feats = feats\n",
        "            return (feats,) if self.use_cbam else None\n",
        "\n",
        "        self._detect_hook_handle = detect_module.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "    @staticmethod\n",
        "    def _pick_high_res_from_detect_inputs(feats):\n",
        "        if not isinstance(feats, (list, tuple)) or len(feats) == 0:\n",
        "            raise RuntimeError(\"Detect input features not captured.\")\n",
        "        return max(feats, key=lambda t: t.shape[-2] * t.shape[-1])\n",
        "\n",
        "    @staticmethod\n",
        "    def _pick_low_res_from_detect_inputs(feats):\n",
        "        if not isinstance(feats, (list, tuple)) or len(feats) == 0:\n",
        "            raise RuntimeError(\"Detect input features not captured.\")\n",
        "        return min(feats, key=lambda t: t.shape[-2] * t.shape[-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TRAIN: x is a batch dict -> YOLO returns (det_loss, loss_items)\n",
        "        if isinstance(x, dict):\n",
        "            self._neck_feats = None\n",
        "            imgs = x[\"img\"]\n",
        "            det_loss, det_items = self.yolo(x)\n",
        "\n",
        "            feat_seg = self._pick_high_res_from_detect_inputs(self._neck_feats)\n",
        "            seg_logits = self.sem_head(feat_seg)\n",
        "            seg_logits = F.interpolate(seg_logits, size=imgs.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "            feat_dn = self._pick_low_res_from_detect_inputs(self._neck_feats)\n",
        "            dn_logits = self.dn_head(feat_dn)\n",
        "\n",
        "            return det_loss, det_items, seg_logits, dn_logits\n",
        "\n",
        "        # INFER: x is an image tensor -> YOLO returns preds\n",
        "        self._neck_feats = None\n",
        "        det_preds = self.yolo(x)\n",
        "\n",
        "        feat_seg = self._pick_high_res_from_detect_inputs(self._neck_feats)\n",
        "        seg_logits = self.sem_head(feat_seg)\n",
        "        seg_logits = F.interpolate(seg_logits, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        feat_dn = self._pick_low_res_from_detect_inputs(self._neck_feats)\n",
        "        dn_logits = self.dn_head(feat_dn)\n",
        "\n",
        "        return det_preds, seg_logits, dn_logits"
      ],
      "metadata": {
        "id": "YHDvMDFcvMcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_det_seg(batch):\n",
        "    # batch items: (img, labels, mask, dn)\n",
        "    imgs, labels_list, masks, dns = zip(*batch)\n",
        "\n",
        "    imgs = torch.stack(imgs, 0)         # [B,3,H,W]\n",
        "    masks = torch.stack(masks, 0)       # [B,1,H,W]\n",
        "    dn = torch.tensor(dns, dtype=torch.long)  # [B]\n",
        "\n",
        "    bboxes_all, cls_all, batch_idx_all = [], [], []\n",
        "    for i, lab in enumerate(labels_list):\n",
        "        if lab.numel() == 0:\n",
        "            continue\n",
        "        cls = lab[:, 0:1].long()\n",
        "        bboxes = lab[:, 1:5].float()\n",
        "        bboxes_all.append(bboxes)\n",
        "        cls_all.append(cls)\n",
        "        batch_idx_all.append(torch.full((lab.shape[0],), i, dtype=torch.long))\n",
        "\n",
        "    if len(bboxes_all):\n",
        "        bboxes = torch.cat(bboxes_all, 0)\n",
        "        cls = torch.cat(cls_all, 0)\n",
        "        batch_idx = torch.cat(batch_idx_all, 0)\n",
        "    else:\n",
        "        bboxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "        cls = torch.zeros((0, 1), dtype=torch.long)\n",
        "        batch_idx = torch.zeros((0,), dtype=torch.long)\n",
        "\n",
        "\n",
        "    yolo_batch = {\"img\": imgs, \"bboxes\": bboxes, \"cls\": cls, \"batch_idx\": batch_idx}\n",
        "\n",
        "\n",
        "    return yolo_batch, masks, dn\n",
        "\n"
      ],
      "metadata": {
        "id": "IV5mygh9vPJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def val_iou(model, loader, device, max_batches=None):\n",
        "    model.eval()\n",
        "    total_iou = 0.0\n",
        "    total_imgs = 0\n",
        "\n",
        "    for bi, (det_batch, mask, dn) in enumerate(loader):\n",
        "        if (max_batches is not None) and (bi >= max_batches):\n",
        "            break\n",
        "\n",
        "        det_batch = {k: v.to(device, non_blocking=True) for k, v in det_batch.items()}\n",
        "        gt = (mask.to(device, non_blocking=True) > 0.5).float()\n",
        "\n",
        "        det_loss, det_items, seg_logits, dn_logits = model(det_batch)  # dict-path returns 4\n",
        "        pred = (torch.sigmoid(seg_logits) > 0.5).float()\n",
        "\n",
        "        inter = (pred * gt).sum(dim=(1, 2, 3))\n",
        "        union = ((pred + gt) > 0).float().sum(dim=(1, 2, 3)).clamp_min(1.0)\n",
        "\n",
        "        iou = inter / union\n",
        "        total_iou += iou.sum().item()\n",
        "        total_imgs += iou.numel()\n",
        "\n",
        "    return total_iou / max(1, total_imgs)\n"
      ],
      "metadata": {
        "id": "Gwg74NkmvQFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = BDDDetDrivableDataset(\n",
        "    yolo_root=\"/content/BDD100K_640/yolo_640\",\n",
        "    mask_root=\"/content/BDD100K_640/drivable_masks_640\",\n",
        "    split=\"val\",\n",
        "    imgsz=640,\n",
        "    dn_csv_path=\"/content/daynight_labels.csv\"\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        "    persistent_workers=False,\n",
        "    collate_fn=collate_det_seg\n",
        ")"
      ],
      "metadata": {
        "id": "-_XbaQffvTP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# PERTURBATION TEST (DET+SEG+DN + CBAM)\n",
        "# mask top-attended vs random (same area) and compare IoU drop\n",
        "\n",
        "\n",
        "import os, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# paths\n",
        "cbam_best_pt = \"/content/drive/MyDrive/XAI_Project/experiments/det_seg_dn_cbam_640/weights/best.pt\"\n",
        "det_base_pt  = \"/content/drive/MyDrive/XAI_Project/experiments/det_baseline/weights/best.pt\"\n",
        "\n",
        "# settings\n",
        "\n",
        "IMG_SIZE = 640\n",
        "TOP_P    = 0.30\n",
        "FILL01   = 114/255.0\n",
        "N        = 1000  # how many images to test\n",
        "PATCH_H = 128\n",
        "PATCH_W = 128\n",
        "SEED_MASK = 1234\n",
        "rng = np.random.default_rng(SEED_MASK)\n",
        "\n",
        "\n",
        "# helpers\n",
        "def make_top_mask(att01, nonpad_mask, top_p=0.15):\n",
        "    vals = att01[nonpad_mask]\n",
        "    thr = np.quantile(vals, 1.0 - top_p)\n",
        "    return (att01 >= thr) & nonpad_mask\n",
        "\n",
        "def make_rand_mask(nonpad_mask, k):\n",
        "    ys, xs = np.where(nonpad_mask)\n",
        "    sel = rng.choice(len(ys), size=k, replace=False)\n",
        "    m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "    m[ys[sel], xs[sel]] = True\n",
        "    return m\n",
        "\n",
        "def apply_mask_to_x_from_img(x, img_np_u8, mask_hw):\n",
        "    # x: [1,3,H,W] float in [0,1]\n",
        "    # img_np_u8: HxWx3 uint8 (same image)\n",
        "    # mask_hw: HxW bool\n",
        "\n",
        "    img2 = img_np_u8.copy()\n",
        "    img2[mask_hw] = 114  # set masked pixels to true padding gray in uint8\n",
        "    x2 = torch.from_numpy(img2).permute(2,0,1).float() / 255.0\n",
        "    return x2.unsqueeze(0).to(x.device)\n",
        "\n",
        "\n",
        "def iou_bin(pred01, gt01):\n",
        "    p = pred01.astype(bool); g = gt01.astype(bool)\n",
        "    inter = (p & g).sum()\n",
        "    union = (p | g).sum()\n",
        "    return float(inter) / float(union + 1e-6)\n",
        "\n",
        "def bbox_from_mask(m):\n",
        "    ys, xs = np.where(m)\n",
        "    if len(ys) == 0:\n",
        "        return None\n",
        "    y1, y2 = ys.min(), ys.max() + 1\n",
        "    x1, x2 = xs.min(), xs.max() + 1\n",
        "    return y1, x1, y2, x2\n",
        "\n",
        "def random_bbox(valid_mask, h, w, tries=200):\n",
        "    H, W = valid_mask.shape\n",
        "    for _ in range(tries):\n",
        "        y1 = np.random.randint(0, H - h + 1)\n",
        "        x1 = np.random.randint(0, W - w + 1)\n",
        "        patch = valid_mask[y1:y1+h, x1:x1+w]\n",
        "        # require most of the patch to be valid (not padding)\n",
        "        if patch.mean() > 0.9:\n",
        "            return y1, x1, y1+h, x1+w\n",
        "    return None\n",
        "\n",
        "def clamp(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def patch_mask_from_center(nonpad_mask, cy, cx, ph, pw):\n",
        "    H, W = nonpad_mask.shape\n",
        "    y1 = clamp(cy - ph//2, 0, H - ph)\n",
        "    x1 = clamp(cx - pw//2, 0, W - pw)\n",
        "    y2, x2 = y1 + ph, x1 + pw\n",
        "    m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "    m[y1:y2, x1:x2] = True\n",
        "    return m & nonpad_mask\n",
        "\n",
        "def random_patch_mask(nonpad_mask, ph, pw, tries=200):\n",
        "    H, W = nonpad_mask.shape\n",
        "    for _ in range(tries):\n",
        "        y1 = int(rng.integers(0, H - ph + 1))\n",
        "        x1 = int(rng.integers(0, W - pw + 1))\n",
        "        patch = nonpad_mask[y1:y1+ph, x1:x1+pw]\n",
        "        if patch.mean() > 0.95:\n",
        "            m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "            m[y1:y1+ph, x1:x1+pw] = True\n",
        "            return m\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_pad_mask_rgb_u8(img_u8, pad_val=114, tol=3):\n",
        "    diff = np.abs(img_u8.astype(np.int16) - pad_val)\n",
        "    return (diff[...,0] <= tol) & (diff[...,1] <= tol) & (diff[...,2] <= tol)\n",
        "\n",
        "# building CBAM det+seg+dn model\n",
        "model = YOLOv8DetSemSegDn(yolo_weights=det_base_pt, use_cbam=True).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    _ = model(torch.zeros(1,3,IMG_SIZE,IMG_SIZE, device=device))\n",
        "\n",
        "\n",
        "ckpt = torch.load(cbam_best_pt, map_location=\"cpu\")\n",
        "sd = ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else ckpt\n",
        "model.load_state_dict(sd, strict=True)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# hook all 3 cbam_neck spatial conv outputs\n",
        "_att = {\"logits_list\": []}\n",
        "def _hook_sa_logits(mod, inp, out):\n",
        "    _att[\"logits_list\"].append(out.detach())\n",
        "\n",
        "handles = []\n",
        "for i in range(3):\n",
        "    handles.append(model.cbam_neck[i].sa.conv.register_forward_hook(_hook_sa_logits))\n",
        "\n",
        "# choose indices\n",
        "SEED_POOL = 42\n",
        "rng_pool = np.random.default_rng(SEED_POOL)\n",
        "idxs = rng_pool.choice(len(val_ds), size=min(1000, len(val_ds)), replace=False).tolist()\n",
        "\n",
        "\n",
        "drops_top, drops_rand = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx in idxs:\n",
        "        sample = val_ds[idx]\n",
        "        img_t   = sample[0]          # [3,640,640]\n",
        "        gt_mask = sample[2]          # <-- if your gt mask is not at [2], change THIS ONE LINE\n",
        "\n",
        "        if torch.is_tensor(gt_mask):\n",
        "            gt_mask = gt_mask[0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        img_np = (img_t.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
        "        H, W = img_np.shape[:2]\n",
        "\n",
        "        pad_mask = get_pad_mask_rgb_u8(img_np, pad_val=114, tol=3)\n",
        "        nonpad_mask = ~pad_mask\n",
        "\n",
        "        x = img_t.unsqueeze(0).to(device)\n",
        "\n",
        "        # clean forward (collect attention)\n",
        "        _att[\"logits_list\"].clear()\n",
        "        det_out, seg_logits, tag_logits = model(x)\n",
        "\n",
        "\n",
        "        # fuse attention (sigmoid each scale, upsample, weighted avg)\n",
        "        fused = torch.zeros((H, W), device=device, dtype=torch.float32)\n",
        "        wsum = 0.0\n",
        "        for logits in _att[\"logits_list\"]:\n",
        "            sa = torch.sigmoid(logits)[0,0]  # [h,w]\n",
        "            h, w = int(sa.shape[-2]), int(sa.shape[-1])\n",
        "            sa_up = F.interpolate(sa[None,None], size=(H,W), mode=\"bilinear\", align_corners=False)[0,0]\n",
        "            weight = float(h*w)\n",
        "            fused += weight * sa_up\n",
        "            wsum  += weight\n",
        "        fused = fused / (wsum + 1e-6)\n",
        "        fused = fused.masked_fill(torch.from_numpy(pad_mask).to(device), 0.0)\n",
        "        att01 = fused.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "        vals = att01[nonpad_mask]\n",
        "        lo = np.quantile(vals, 0.05)\n",
        "        hi = np.quantile(vals, 0.95)\n",
        "        att01 = np.clip((att01 - lo) / (hi - lo + 1e-6), 0.0, 1.0).astype(np.float32)\n",
        "        att01[pad_mask] = 0.0\n",
        "\n",
        "\n",
        "        # segmentation clean\n",
        "        pred_clean = (torch.sigmoid(seg_logits)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "        iou_clean = iou_bin(pred_clean, gt_mask)\n",
        "\n",
        "\n",
        "      # masks (fixed-size patches)\n",
        "        top_pix = make_top_mask(att01, nonpad_mask, TOP_P)   # TOP_P is fine (0.30)\n",
        "\n",
        "        ys, xs = np.where(top_pix)\n",
        "        if len(ys) == 0:\n",
        "            continue\n",
        "        cy = int(np.mean(ys))\n",
        "        cx = int(np.mean(xs))\n",
        "\n",
        "        top_mask = patch_mask_from_center(nonpad_mask, cy, cx, PATCH_H, PATCH_W)\n",
        "\n",
        "\n",
        "        rand_mask = random_patch_mask(nonpad_mask, PATCH_H, PATCH_W)\n",
        "        if rand_mask is None:\n",
        "            continue\n",
        "\n",
        "\n",
        "        # perturbed inputs\n",
        "        x_top  = apply_mask_to_x_from_img(x, img_np, top_mask)\n",
        "        x_rand = apply_mask_to_x_from_img(x, img_np, rand_mask)\n",
        "\n",
        "\n",
        "        # forwards perturbed\n",
        "        _, seg_top,  _ = model(x_top)\n",
        "        _, seg_rand, _ = model(x_rand)\n",
        "\n",
        "\n",
        "        pred_top  = (torch.sigmoid(seg_top)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "        pred_rand = (torch.sigmoid(seg_rand)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        iou_top  = iou_bin(pred_top, gt_mask)\n",
        "        iou_rand = iou_bin(pred_rand, gt_mask)\n",
        "\n",
        "        drops_top.append(iou_clean - iou_top)\n",
        "        drops_rand.append(iou_clean - iou_rand)\n",
        "\n",
        "# cleanup hooks\n",
        "for h in handles:\n",
        "    h.remove()\n",
        "\n",
        "print(\"Images used:\", len(drops_top))\n",
        "print(\"Mean IoU drop (top-att):\", float(np.mean(drops_top)) if drops_top else None)\n",
        "print(\"Mean IoU drop (random):\",  float(np.mean(drops_rand)) if drops_rand else None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUefOwB289Li",
        "outputId": "14d345a5-8c8e-45f5-c264-1635637841e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images used: 1000\n",
            "Mean IoU drop (top-att): 0.16929898551437883\n",
            "Mean IoU drop (random): 0.09067801369320716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# PERTURBATION TEST (DET+SEG+DN + CBAM)\n",
        "# mask top-attended vs random (same area) and compare IoU drop\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# paths\n",
        "cbam_best_pt = \"/content/drive/MyDrive/XAI_Project/experiments/det_seg_dn_cbam_640/weights/best.pt\"\n",
        "det_base_pt  = \"/content/drive/MyDrive/XAI_Project/experiments/det_baseline/weights/best.pt\"\n",
        "\n",
        "# settings\n",
        "\n",
        "IMG_SIZE = 640\n",
        "TOP_P    = 0.30\n",
        "FILL01   = 114/255.0\n",
        "N        = 1000  # how many images to test\n",
        "PATCH_H = 128\n",
        "PATCH_W = 128\n",
        "SEED_MASK = 1234\n",
        "rng = np.random.default_rng(SEED_MASK)\n",
        "\n",
        "\n",
        "# helpers\n",
        "def make_top_mask(att01, nonpad_mask, top_p=0.15):\n",
        "    vals = att01[nonpad_mask]\n",
        "    thr = np.quantile(vals, 1.0 - top_p)\n",
        "    return (att01 >= thr) & nonpad_mask\n",
        "\n",
        "def make_rand_mask(nonpad_mask, k):\n",
        "    ys, xs = np.where(nonpad_mask)\n",
        "    sel = rng.choice(len(ys), size=k, replace=False)\n",
        "    m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "    m[ys[sel], xs[sel]] = True\n",
        "    return m\n",
        "\n",
        "def apply_mask_to_x_from_img(x, img_np_u8, mask_hw):\n",
        "    img2 = img_np_u8.copy()\n",
        "    img2[mask_hw] = 114\n",
        "    x2 = torch.from_numpy(img2).permute(2,0,1).float() / 255.0\n",
        "    return x2.unsqueeze(0).to(x.device), img2   # <- return BOTH\n",
        "\n",
        "\n",
        "\n",
        "def iou_bin(pred01, gt01):\n",
        "    p = pred01.astype(bool); g = gt01.astype(bool)\n",
        "    inter = (p & g).sum()\n",
        "    union = (p | g).sum()\n",
        "    return float(inter) / float(union + 1e-6)\n",
        "\n",
        "def bbox_from_mask(m):\n",
        "    ys, xs = np.where(m)\n",
        "    if len(ys) == 0:\n",
        "        return None\n",
        "    y1, y2 = ys.min(), ys.max() + 1\n",
        "    x1, x2 = xs.min(), xs.max() + 1\n",
        "    return y1, x1, y2, x2\n",
        "\n",
        "def random_bbox(valid_mask, h, w, tries=200):\n",
        "    H, W = valid_mask.shape\n",
        "    for _ in range(tries):\n",
        "        y1 = np.random.randint(0, H - h + 1)\n",
        "        x1 = np.random.randint(0, W - w + 1)\n",
        "        patch = valid_mask[y1:y1+h, x1:x1+w]\n",
        "        # require most of the patch to be valid (not padding)\n",
        "        if patch.mean() > 0.9:\n",
        "            return y1, x1, y1+h, x1+w\n",
        "    return None\n",
        "\n",
        "def clamp(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def patch_mask_from_center(nonpad_mask, cy, cx, ph, pw):\n",
        "    H, W = nonpad_mask.shape\n",
        "    y1 = clamp(cy - ph//2, 0, H - ph)\n",
        "    x1 = clamp(cx - pw//2, 0, W - pw)\n",
        "    y2, x2 = y1 + ph, x1 + pw\n",
        "    m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "    m[y1:y2, x1:x2] = True\n",
        "    return m & nonpad_mask\n",
        "\n",
        "def random_patch_mask(nonpad_mask, ph, pw, tries=200):\n",
        "    H, W = nonpad_mask.shape\n",
        "    for _ in range(tries):\n",
        "        y1 = int(rng.integers(0, H - ph + 1))\n",
        "        x1 = int(rng.integers(0, W - pw + 1))\n",
        "        patch = nonpad_mask[y1:y1+ph, x1:x1+pw]\n",
        "        if patch.mean() > 0.95:\n",
        "            m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "            m[y1:y1+ph, x1:x1+pw] = True\n",
        "            return m\n",
        "    return None\n",
        "\n",
        "def yolo_xywhn_to_xyxy_px(labels_xywhn, H, W):\n",
        "    \"\"\"\n",
        "    labels_xywhn: array Nx5 => [cls, x, y, w, h] normalized (YOLO format)\n",
        "    returns: list of (cls, x1,y1,x2,y2)\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    if labels_xywhn is None:\n",
        "        return out\n",
        "    arr = np.array(labels_xywhn)\n",
        "    if arr.size == 0:\n",
        "        return out\n",
        "    arr = arr.reshape(-1, arr.shape[-1])\n",
        "\n",
        "    # if tensor\n",
        "    if torch.is_tensor(labels_xywhn):\n",
        "        arr = labels_xywhn.detach().cpu().numpy()\n",
        "\n",
        "    for row in arr:\n",
        "        if len(row) < 5:\n",
        "            continue\n",
        "        cls, x, y, w, h = row[:5]\n",
        "        x1 = (x - w/2) * W\n",
        "        y1 = (y - h/2) * H\n",
        "        x2 = (x + w/2) * W\n",
        "        y2 = (y + h/2) * H\n",
        "        out.append((int(cls), float(x1), float(y1), float(x2), float(y2)))\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_gt_boxes_from_sample(sample, H, W):\n",
        "    \"\"\"\n",
        "    Tries to extract GT detection boxes from val_ds sample.\n",
        "    Common cases:\n",
        "      - sample[1] is Nx5 tensor/array: [cls, x, y, w, h] normalized (YOLO labels)\n",
        "    \"\"\"\n",
        "    if len(sample) < 2:\n",
        "        return []\n",
        "    gt = sample[1]\n",
        "\n",
        "    # case: tensor/ndarray Nx5\n",
        "    if torch.is_tensor(gt) or isinstance(gt, (np.ndarray, list, tuple)):\n",
        "        try:\n",
        "            return yolo_xywhn_to_xyxy_px(gt, H, W)\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "    return []\n",
        "\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    # a,b: (x1,y1,x2,y2)\n",
        "    ax1, ay1, ax2, ay2 = a\n",
        "    bx1, by1, bx2, by2 = b\n",
        "    ix1, iy1 = max(ax1, bx1), max(ay1, by1)\n",
        "    ix2, iy2 = min(ax2, bx2), min(ay2, by2)\n",
        "    iw, ih = max(0.0, ix2 - ix1), max(0.0, iy2 - iy1)\n",
        "    inter = iw * ih\n",
        "    area_a = max(0.0, ax2-ax1) * max(0.0, ay2-ay1)\n",
        "    area_b = max(0.0, bx2-bx1) * max(0.0, by2-by1)\n",
        "    return inter / (area_a + area_b - inter + 1e-6)\n",
        "\n",
        "\n",
        "def ap50_single_image(preds, gts, iou_thr=0.50):\n",
        "    \"\"\"\n",
        "    preds: list of (cls, conf, x1,y1,x2,y2)\n",
        "    gts:   list of (cls, x1,y1,x2,y2)\n",
        "\n",
        "    Returns AP@0.50 computed on THIS image, across all classes (micro).\n",
        "    This is \"mAP-like\" (not dataset mAP), good for perturbation comparison.\n",
        "    \"\"\"\n",
        "    if len(gts) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # sort predictions by confidence desc\n",
        "    preds = sorted(preds, key=lambda t: t[1], reverse=True)\n",
        "\n",
        "    gt_used = [False] * len(gts)\n",
        "    tp = np.zeros(len(preds), dtype=np.float32)\n",
        "    fp = np.zeros(len(preds), dtype=np.float32)\n",
        "\n",
        "    for i, (pc, conf, px1, py1, px2, py2) in enumerate(preds):\n",
        "        best_j = -1\n",
        "        best_iou = 0.0\n",
        "        for j, (gc, gx1, gy1, gx2, gy2) in enumerate(gts):\n",
        "            if gt_used[j]:\n",
        "                continue\n",
        "            if pc != gc:\n",
        "                continue\n",
        "            iou = iou_xyxy((px1,py1,px2,py2), (gx1,gy1,gx2,gy2))\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_j = j\n",
        "\n",
        "        if best_j >= 0 and best_iou >= iou_thr:\n",
        "            tp[i] = 1.0\n",
        "            gt_used[best_j] = True\n",
        "        else:\n",
        "            fp[i] = 1.0\n",
        "\n",
        "    cum_tp = np.cumsum(tp)\n",
        "    cum_fp = np.cumsum(fp)\n",
        "    recall = cum_tp / (len(gts) + 1e-6)\n",
        "    precision = cum_tp / (cum_tp + cum_fp + 1e-6)\n",
        "\n",
        "    # AP by 11-point interpolation (simple + stable)\n",
        "    ap = 0.0\n",
        "    for r in np.linspace(0, 1, 11):\n",
        "        p = precision[recall >= r].max() if np.any(recall >= r) else 0.0\n",
        "        ap += p / 11.0\n",
        "    return float(ap)\n",
        "\n",
        "\n",
        "def det_predict_boxes(det_eval, img_np_u8, conf=0.25, iou=0.6):\n",
        "    \"\"\"\n",
        "    Returns list of (cls, conf, x1,y1,x2,y2) in pixel coords.\n",
        "    \"\"\"\n",
        "    res = det_eval.predict(source=img_np_u8, imgsz=img_np_u8.shape[0], conf=conf, iou=iou, verbose=False)[0]\n",
        "    if res.boxes is None or len(res.boxes) == 0:\n",
        "        return []\n",
        "    xyxy = res.boxes.xyxy.detach().cpu().numpy()\n",
        "    cls  = res.boxes.cls.detach().cpu().numpy().astype(int)\n",
        "    cf   = res.boxes.conf.detach().cpu().numpy()\n",
        "    out = []\n",
        "    for (x1,y1,x2,y2), c, p in zip(xyxy, cls, cf):\n",
        "        out.append((int(c), float(p), float(x1), float(y1), float(x2), float(y2)))\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def get_pad_mask_rgb_u8(img_u8, pad_val=114, tol=3):\n",
        "    diff = np.abs(img_u8.astype(np.int16) - pad_val)\n",
        "    return (diff[...,0] <= tol) & (diff[...,1] <= tol) & (diff[...,2] <= tol)\n",
        "\n",
        "# building CBAM det+seg+dn model\n",
        "model = YOLOv8DetSemSegDn(yolo_weights=det_base_pt, use_cbam=True).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    _ = model(torch.zeros(1,3,IMG_SIZE,IMG_SIZE, device=device))\n",
        "\n",
        "\n",
        "ckpt = torch.load(cbam_best_pt, map_location=\"cpu\")\n",
        "sd = ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else ckpt\n",
        "model.load_state_dict(sd, strict=True)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# a YOLO \"shell\" just to host the loaded weights (any yolov8n.pt / your det baseline pt works)\n",
        "det_shell = det_base_pt\n",
        "det_eval = YOLO(det_shell)\n",
        "\n",
        "# class names (your 5 classes)\n",
        "det_eval.model.names = {0:\"car\", 1:\"truck\", 2:\"bus\", 3:\"person\", 4:\"bike\"}\n",
        "\n",
        "# load YOLO submodule weights from your tri-task checkpoint (sd)\n",
        "yolo_sd = {k.replace(\"yolo.\", \"\"): v for k, v in sd.items() if k.startswith(\"yolo.\")}\n",
        "det_eval.model.load_state_dict(yolo_sd, strict=False)\n",
        "det_eval.fuse()\n",
        "\n",
        "\n",
        "# hook all 3 cbam_neck spatial conv outputs\n",
        "_att = {\"logits_list\": []}\n",
        "def _hook_sa_logits(mod, inp, out):\n",
        "    _att[\"logits_list\"].append(out.detach())\n",
        "\n",
        "handles = []\n",
        "for i in range(3):\n",
        "    handles.append(model.cbam_neck[i].sa.conv.register_forward_hook(_hook_sa_logits))\n",
        "\n",
        "# choose indices\n",
        "SEED_POOL = 42\n",
        "rng_pool = np.random.default_rng(SEED_POOL)\n",
        "idxs = rng_pool.choice(len(val_ds), size=min(1000, len(val_ds)), replace=False).tolist()\n",
        "\n",
        "\n",
        "drops_top, drops_rand = [], []\n",
        "ap_drops_top  = []\n",
        "ap_drops_rand = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx in idxs:\n",
        "        sample = val_ds[idx]\n",
        "        img_t   = sample[0]          # [3,640,640]\n",
        "        gt_mask = sample[2]          # <-- if your gt mask is not at [2], change THIS ONE LINE\n",
        "\n",
        "        if torch.is_tensor(gt_mask):\n",
        "            gt_mask = gt_mask[0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        img_np = (img_t.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
        "        H, W = img_np.shape[:2]\n",
        "\n",
        "        gt_boxes = get_gt_boxes_from_sample(sample, H, W)  # list of (cls,x1,y1,x2,y2)\n",
        "\n",
        "\n",
        "        pad_mask = get_pad_mask_rgb_u8(img_np, pad_val=114, tol=3)\n",
        "        nonpad_mask = ~pad_mask\n",
        "\n",
        "        x = img_t.unsqueeze(0).to(device)\n",
        "\n",
        "        # clean forward (collect attention)\n",
        "        _att[\"logits_list\"].clear()\n",
        "        det_out, seg_logits, tag_logits = model(x)\n",
        "\n",
        "        pred_det_clean = det_predict_boxes(det_eval, img_np, conf=0.25, iou=0.6)\n",
        "        ap_clean = ap50_single_image(pred_det_clean, gt_boxes, iou_thr=0.50)\n",
        "\n",
        "\n",
        "\n",
        "        # fuse attention (sigmoid each scale, upsample, weighted avg)\n",
        "        fused = torch.zeros((H, W), device=device, dtype=torch.float32)\n",
        "        wsum = 0.0\n",
        "        for logits in _att[\"logits_list\"]:\n",
        "            sa = torch.sigmoid(logits)[0,0]  # [h,w]\n",
        "            h, w = int(sa.shape[-2]), int(sa.shape[-1])\n",
        "            sa_up = F.interpolate(sa[None,None], size=(H,W), mode=\"bilinear\", align_corners=False)[0,0]\n",
        "            weight = float(h*w)\n",
        "            fused += weight * sa_up\n",
        "            wsum  += weight\n",
        "        fused = fused / (wsum + 1e-6)\n",
        "        fused = fused.masked_fill(torch.from_numpy(pad_mask).to(device), 0.0)\n",
        "        att01 = fused.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "        vals = att01[nonpad_mask]\n",
        "        lo = np.quantile(vals, 0.05)\n",
        "        hi = np.quantile(vals, 0.95)\n",
        "        att01 = np.clip((att01 - lo) / (hi - lo + 1e-6), 0.0, 1.0).astype(np.float32)\n",
        "        att01[pad_mask] = 0.0\n",
        "\n",
        "\n",
        "        # segmentation clean\n",
        "        pred_clean = (torch.sigmoid(seg_logits)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "        iou_clean = iou_bin(pred_clean, gt_mask)\n",
        "\n",
        "\n",
        "      # masks (fixed-size patches)\n",
        "        top_pix = make_top_mask(att01, nonpad_mask, TOP_P)   # TOP_P is fine (0.30)\n",
        "\n",
        "        ys, xs = np.where(top_pix)\n",
        "        if len(ys) == 0:\n",
        "            continue\n",
        "        cy = int(np.mean(ys))\n",
        "        cx = int(np.mean(xs))\n",
        "\n",
        "        top_mask = patch_mask_from_center(nonpad_mask, cy, cx, PATCH_H, PATCH_W)\n",
        "\n",
        "\n",
        "        rand_mask = random_patch_mask(nonpad_mask, PATCH_H, PATCH_W)\n",
        "        if rand_mask is None:\n",
        "            continue\n",
        "\n",
        "\n",
        "        # perturbed inputs\n",
        "        x_top,  img_top_np  = apply_mask_to_x_from_img(x, img_np, top_mask)\n",
        "        x_rand, img_rand_np = apply_mask_to_x_from_img(x, img_np, rand_mask)\n",
        "\n",
        "\n",
        "\n",
        "        # forwards perturbed\n",
        "        _, seg_top,  _ = model(x_top)\n",
        "        _, seg_rand, _ = model(x_rand)\n",
        "\n",
        "        pred_det_top  = det_predict_boxes(det_eval, img_top_np,  conf=0.25, iou=0.6)\n",
        "        pred_det_rand = det_predict_boxes(det_eval, img_rand_np, conf=0.25, iou=0.6)\n",
        "\n",
        "        ap_top  = ap50_single_image(pred_det_top,  gt_boxes, iou_thr=0.50)\n",
        "        ap_rand = ap50_single_image(pred_det_rand, gt_boxes, iou_thr=0.50)\n",
        "\n",
        "        ap_drops_top.append(ap_clean - ap_top)\n",
        "        ap_drops_rand.append(ap_clean - ap_rand)\n",
        "\n",
        "\n",
        "\n",
        "        pred_top  = (torch.sigmoid(seg_top)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "        pred_rand = (torch.sigmoid(seg_rand)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        iou_top  = iou_bin(pred_top, gt_mask)\n",
        "        iou_rand = iou_bin(pred_rand, gt_mask)\n",
        "\n",
        "        drops_top.append(iou_clean - iou_top)\n",
        "        drops_rand.append(iou_clean - iou_rand)\n",
        "\n",
        "# cleanup hooks\n",
        "for h in handles:\n",
        "    h.remove()\n",
        "\n",
        "print(\"Images used:\", len(drops_top))\n",
        "print(\"Mean IoU drop (top-att):\", float(np.mean(drops_top)) if drops_top else None)\n",
        "print(\"Mean IoU drop (random):\",  float(np.mean(drops_rand)) if drops_rand else None)\n",
        "print(\"Mean AP50 drop (top-att):\",  float(np.mean(ap_drops_top)) if ap_drops_top else None)\n",
        "print(\"Mean AP50 drop (random):\",   float(np.mean(ap_drops_rand)) if ap_drops_rand else None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzow5O9R8XJG",
        "outputId": "4f528547-3f24-459a-a451-8b79e1a8fc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
            "Images used: 1000\n",
            "Mean IoU drop (top-att): 0.16929898551437883\n",
            "Mean IoU drop (random): 0.09067801369320716\n",
            "Mean AP50 drop (top-att): 0.019582364522153513\n",
            "Mean AP50 drop (random): 0.009320265210873913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PERTURBATION TEST (DET+SEG+DN + CBAM)\n",
        "# mask top-attended vs random (same area) and compare IoU drop\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# paths\n",
        "cbam_best_pt = \"/content/drive/MyDrive/XAI_Project/experiments/det_seg_dn_cbam_640/weights/best.pt\"\n",
        "det_base_pt  = \"/content/drive/MyDrive/XAI_Project/experiments/det_baseline/weights/best.pt\"\n",
        "\n",
        "# settings\n",
        "\n",
        "IMG_SIZE = 640\n",
        "TOP_P    = 0.30\n",
        "FILL01   = 114/255.0\n",
        "N        = 1000  # how many images to test\n",
        "PATCH_H = 128\n",
        "PATCH_W = 128\n",
        "SEED_MASK = 1234\n",
        "DN_INDEX = 3\n",
        "rng = np.random.default_rng(SEED_MASK)\n",
        "\n",
        "\n",
        "# helpers\n",
        "def make_top_mask(att01, nonpad_mask, top_p=0.15):\n",
        "    vals = att01[nonpad_mask]\n",
        "    thr = np.quantile(vals, 1.0 - top_p)\n",
        "    return (att01 >= thr) & nonpad_mask\n",
        "\n",
        "def make_rand_mask(nonpad_mask, k):\n",
        "    ys, xs = np.where(nonpad_mask)\n",
        "    sel = rng.choice(len(ys), size=k, replace=False)\n",
        "    m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "    m[ys[sel], xs[sel]] = True\n",
        "    return m\n",
        "\n",
        "def apply_mask_to_x_from_img(x, img_np_u8, mask_hw):\n",
        "    img2 = img_np_u8.copy()\n",
        "    img2[mask_hw] = 114\n",
        "    x2 = torch.from_numpy(img2).permute(2,0,1).float() / 255.0\n",
        "    return x2.unsqueeze(0).to(x.device), img2   # <- return BOTH\n",
        "\n",
        "\n",
        "\n",
        "def iou_bin(pred01, gt01):\n",
        "    p = pred01.astype(bool); g = gt01.astype(bool)\n",
        "    inter = (p & g).sum()\n",
        "    union = (p | g).sum()\n",
        "    return float(inter) / float(union + 1e-6)\n",
        "\n",
        "def bbox_from_mask(m):\n",
        "    ys, xs = np.where(m)\n",
        "    if len(ys) == 0:\n",
        "        return None\n",
        "    y1, y2 = ys.min(), ys.max() + 1\n",
        "    x1, x2 = xs.min(), xs.max() + 1\n",
        "    return y1, x1, y2, x2\n",
        "\n",
        "def random_bbox(valid_mask, h, w, tries=200):\n",
        "    H, W = valid_mask.shape\n",
        "    for _ in range(tries):\n",
        "        y1 = np.random.randint(0, H - h + 1)\n",
        "        x1 = np.random.randint(0, W - w + 1)\n",
        "        patch = valid_mask[y1:y1+h, x1:x1+w]\n",
        "        # require most of the patch to be valid (not padding)\n",
        "        if patch.mean() > 0.9:\n",
        "            return y1, x1, y1+h, x1+w\n",
        "    return None\n",
        "\n",
        "def clamp(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def patch_mask_from_center(nonpad_mask, cy, cx, ph, pw):\n",
        "    H, W = nonpad_mask.shape\n",
        "    y1 = clamp(cy - ph//2, 0, H - ph)\n",
        "    x1 = clamp(cx - pw//2, 0, W - pw)\n",
        "    y2, x2 = y1 + ph, x1 + pw\n",
        "    m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "    m[y1:y2, x1:x2] = True\n",
        "    return m & nonpad_mask\n",
        "\n",
        "def random_patch_mask(nonpad_mask, ph, pw, tries=200):\n",
        "    H, W = nonpad_mask.shape\n",
        "    for _ in range(tries):\n",
        "        y1 = int(rng.integers(0, H - ph + 1))\n",
        "        x1 = int(rng.integers(0, W - pw + 1))\n",
        "        patch = nonpad_mask[y1:y1+ph, x1:x1+pw]\n",
        "        if patch.mean() > 0.95:\n",
        "            m = np.zeros_like(nonpad_mask, dtype=bool)\n",
        "            m[y1:y1+ph, x1:x1+pw] = True\n",
        "            return m\n",
        "    return None\n",
        "\n",
        "def yolo_xywhn_to_xyxy_px(labels_xywhn, H, W):\n",
        "    \"\"\"\n",
        "    labels_xywhn: array Nx5 => [cls, x, y, w, h] normalized (YOLO format)\n",
        "    returns: list of (cls, x1,y1,x2,y2)\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    if labels_xywhn is None:\n",
        "        return out\n",
        "    arr = np.array(labels_xywhn)\n",
        "    if arr.size == 0:\n",
        "        return out\n",
        "    arr = arr.reshape(-1, arr.shape[-1])\n",
        "\n",
        "    # if tensor\n",
        "    if torch.is_tensor(labels_xywhn):\n",
        "        arr = labels_xywhn.detach().cpu().numpy()\n",
        "\n",
        "    for row in arr:\n",
        "        if len(row) < 5:\n",
        "            continue\n",
        "        cls, x, y, w, h = row[:5]\n",
        "        x1 = (x - w/2) * W\n",
        "        y1 = (y - h/2) * H\n",
        "        x2 = (x + w/2) * W\n",
        "        y2 = (y + h/2) * H\n",
        "        out.append((int(cls), float(x1), float(y1), float(x2), float(y2)))\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_gt_boxes_from_sample(sample, H, W):\n",
        "    \"\"\"\n",
        "    Tries to extract GT detection boxes from val_ds sample.\n",
        "    Common cases:\n",
        "      - sample[1] is Nx5 tensor/array: [cls, x, y, w, h] normalized (YOLO labels)\n",
        "    \"\"\"\n",
        "    if len(sample) < 2:\n",
        "        return []\n",
        "    gt = sample[1]\n",
        "\n",
        "    # case: tensor/ndarray Nx5\n",
        "    if torch.is_tensor(gt) or isinstance(gt, (np.ndarray, list, tuple)):\n",
        "        try:\n",
        "            return yolo_xywhn_to_xyxy_px(gt, H, W)\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "    return []\n",
        "\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    # a,b: (x1,y1,x2,y2)\n",
        "    ax1, ay1, ax2, ay2 = a\n",
        "    bx1, by1, bx2, by2 = b\n",
        "    ix1, iy1 = max(ax1, bx1), max(ay1, by1)\n",
        "    ix2, iy2 = min(ax2, bx2), min(ay2, by2)\n",
        "    iw, ih = max(0.0, ix2 - ix1), max(0.0, iy2 - iy1)\n",
        "    inter = iw * ih\n",
        "    area_a = max(0.0, ax2-ax1) * max(0.0, ay2-ay1)\n",
        "    area_b = max(0.0, bx2-bx1) * max(0.0, by2-by1)\n",
        "    return inter / (area_a + area_b - inter + 1e-6)\n",
        "\n",
        "\n",
        "def ap50_single_image(preds, gts, iou_thr=0.50):\n",
        "    \"\"\"\n",
        "    preds: list of (cls, conf, x1,y1,x2,y2)\n",
        "    gts:   list of (cls, x1,y1,x2,y2)\n",
        "\n",
        "    Returns AP@0.50 computed on THIS image, across all classes (micro).\n",
        "    This is \"mAP-like\" (not dataset mAP), good for perturbation comparison.\n",
        "    \"\"\"\n",
        "    if len(gts) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # sort predictions by confidence desc\n",
        "    preds = sorted(preds, key=lambda t: t[1], reverse=True)\n",
        "\n",
        "    gt_used = [False] * len(gts)\n",
        "    tp = np.zeros(len(preds), dtype=np.float32)\n",
        "    fp = np.zeros(len(preds), dtype=np.float32)\n",
        "\n",
        "    for i, (pc, conf, px1, py1, px2, py2) in enumerate(preds):\n",
        "        best_j = -1\n",
        "        best_iou = 0.0\n",
        "        for j, (gc, gx1, gy1, gx2, gy2) in enumerate(gts):\n",
        "            if gt_used[j]:\n",
        "                continue\n",
        "            if pc != gc:\n",
        "                continue\n",
        "            iou = iou_xyxy((px1,py1,px2,py2), (gx1,gy1,gx2,gy2))\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_j = j\n",
        "\n",
        "        if best_j >= 0 and best_iou >= iou_thr:\n",
        "            tp[i] = 1.0\n",
        "            gt_used[best_j] = True\n",
        "        else:\n",
        "            fp[i] = 1.0\n",
        "\n",
        "    cum_tp = np.cumsum(tp)\n",
        "    cum_fp = np.cumsum(fp)\n",
        "    recall = cum_tp / (len(gts) + 1e-6)\n",
        "    precision = cum_tp / (cum_tp + cum_fp + 1e-6)\n",
        "\n",
        "    # AP by 11-point interpolation (simple + stable)\n",
        "    ap = 0.0\n",
        "    for r in np.linspace(0, 1, 11):\n",
        "        p = precision[recall >= r].max() if np.any(recall >= r) else 0.0\n",
        "        ap += p / 11.0\n",
        "    return float(ap)\n",
        "\n",
        "\n",
        "def det_predict_boxes(det_eval, img_np_u8, conf=0.25, iou=0.6):\n",
        "    \"\"\"\n",
        "    Returns list of (cls, conf, x1,y1,x2,y2) in pixel coords.\n",
        "    \"\"\"\n",
        "    res = det_eval.predict(source=img_np_u8, imgsz=img_np_u8.shape[0], conf=conf, iou=iou, verbose=False)[0]\n",
        "    if res.boxes is None or len(res.boxes) == 0:\n",
        "        return []\n",
        "    xyxy = res.boxes.xyxy.detach().cpu().numpy()\n",
        "    cls  = res.boxes.cls.detach().cpu().numpy().astype(int)\n",
        "    cf   = res.boxes.conf.detach().cpu().numpy()\n",
        "    out = []\n",
        "    for (x1,y1,x2,y2), c, p in zip(xyxy, cls, cf):\n",
        "        out.append((int(c), float(p), float(x1), float(y1), float(x2), float(y2)))\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_dn_gt(sample, dn_index=DN_INDEX):\n",
        "    dn = sample[dn_index]\n",
        "    # dn can be tensor, numpy scalar, int\n",
        "    if torch.is_tensor(dn):\n",
        "        dn = dn.detach().cpu()\n",
        "        dn = dn.view(-1)[0].item()  # scalar\n",
        "    else:\n",
        "        dn = float(dn)\n",
        "    # make it 0/1\n",
        "    return int(dn >= 0.5)\n",
        "\n",
        "def tag_prob_night_and_pred(tag_logits):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      p_night: float in [0,1]\n",
        "      pred: 0/1  (0=day, 1=night)\n",
        "    Supports:\n",
        "      - sigmoid head: tag_logits shape [B,1] or [B]\n",
        "      - 2-class head: tag_logits shape [B,2]\n",
        "    \"\"\"\n",
        "    t = tag_logits\n",
        "    if torch.is_tensor(t):\n",
        "        t = t.detach()\n",
        "    t = t.view(t.shape[0], -1)  # [B, K]\n",
        "\n",
        "    if t.shape[1] == 2:\n",
        "        # 2-class logits\n",
        "        probs = torch.softmax(t, dim=1)      # [B,2]\n",
        "        p_night = probs[0, 1].item()\n",
        "        pred = int(torch.argmax(probs[0]).item())  # 0/1\n",
        "        return p_night, pred\n",
        "    else:\n",
        "        # sigmoid logit\n",
        "        p_night = torch.sigmoid(t[0, 0]).item()\n",
        "        pred = int(p_night >= 0.5)\n",
        "        return p_night, pred\n",
        "\n",
        "def prob_of_correct_class(p_night, gt_dn):\n",
        "    # gt_dn: 0=day, 1=night\n",
        "    return p_night if gt_dn == 1 else (1.0 - p_night)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_pad_mask_rgb_u8(img_u8, pad_val=114, tol=3):\n",
        "    diff = np.abs(img_u8.astype(np.int16) - pad_val)\n",
        "    return (diff[...,0] <= tol) & (diff[...,1] <= tol) & (diff[...,2] <= tol)\n",
        "\n",
        "# building CBAM det+seg+dn model\n",
        "model = YOLOv8DetSemSegDn(yolo_weights=det_base_pt, use_cbam=True).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    _ = model(torch.zeros(1,3,IMG_SIZE,IMG_SIZE, device=device))\n",
        "\n",
        "\n",
        "ckpt = torch.load(cbam_best_pt, map_location=\"cpu\")\n",
        "sd = ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else ckpt\n",
        "model.load_state_dict(sd, strict=True)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# a YOLO \"shell\" just to host the loaded weights (any yolov8n.pt / your det baseline pt works)\n",
        "det_shell = det_base_pt\n",
        "det_eval = YOLO(det_shell)\n",
        "\n",
        "# class names (your 5 classes)\n",
        "det_eval.model.names = {0:\"car\", 1:\"truck\", 2:\"bus\", 3:\"person\", 4:\"bike\"}\n",
        "\n",
        "# load YOLO submodule weights from your tri-task checkpoint (sd)\n",
        "yolo_sd = {k.replace(\"yolo.\", \"\"): v for k, v in sd.items() if k.startswith(\"yolo.\")}\n",
        "det_eval.model.load_state_dict(yolo_sd, strict=False)\n",
        "det_eval.fuse()\n",
        "\n",
        "\n",
        "# hook all 3 cbam_neck spatial conv outputs\n",
        "_att = {\"logits_list\": []}\n",
        "def _hook_sa_logits(mod, inp, out):\n",
        "    _att[\"logits_list\"].append(out.detach())\n",
        "\n",
        "handles = []\n",
        "for i in range(3):\n",
        "    handles.append(model.cbam_neck[i].sa.conv.register_forward_hook(_hook_sa_logits))\n",
        "\n",
        "# choose indices\n",
        "SEED_POOL = 42\n",
        "rng_pool = np.random.default_rng(SEED_POOL)\n",
        "idxs = rng_pool.choice(len(val_ds), size=min(1000, len(val_ds)), replace=False).tolist()\n",
        "\n",
        "\n",
        "drops_top, drops_rand = [], []\n",
        "ap_drops_top  = []\n",
        "ap_drops_rand = []\n",
        "\n",
        "# tagging accumulators\n",
        "tag_ok_clean = []\n",
        "tag_ok_top   = []\n",
        "tag_ok_rand  = []\n",
        "\n",
        "tag_pok_clean = []\n",
        "tag_pok_top   = []\n",
        "tag_pok_rand  = []\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx in idxs:\n",
        "        sample = val_ds[idx]\n",
        "        img_t   = sample[0]          # [3,640,640]\n",
        "        gt_mask = sample[2]          # <-- if your gt mask is not at [2], change THIS ONE LINE\n",
        "        gt_dn = get_dn_gt(sample)   # 0=day, 1=night\n",
        "\n",
        "        if torch.is_tensor(gt_mask):\n",
        "            gt_mask = gt_mask[0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        img_np = (img_t.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
        "        H, W = img_np.shape[:2]\n",
        "\n",
        "        gt_boxes = get_gt_boxes_from_sample(sample, H, W)  # list of (cls,x1,y1,x2,y2)\n",
        "\n",
        "\n",
        "        pad_mask = get_pad_mask_rgb_u8(img_np, pad_val=114, tol=3)\n",
        "        nonpad_mask = ~pad_mask\n",
        "\n",
        "        x = img_t.unsqueeze(0).to(device)\n",
        "\n",
        "        # clean forward (collect attention)\n",
        "        _att[\"logits_list\"].clear()\n",
        "        det_out, seg_logits, tag_logits = model(x)\n",
        "\n",
        "        pred_det_clean = det_predict_boxes(det_eval, img_np, conf=0.25, iou=0.6)\n",
        "        ap_clean = ap50_single_image(pred_det_clean, gt_boxes, iou_thr=0.50)\n",
        "\n",
        "        p_clean, pred_clean_dn = tag_prob_night_and_pred(tag_logits)\n",
        "        tag_ok_clean.append(int(pred_clean_dn == gt_dn))\n",
        "        tag_pok_clean.append(prob_of_correct_class(p_clean, gt_dn))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # fuse attention (sigmoid each scale, upsample, weighted avg)\n",
        "        fused = torch.zeros((H, W), device=device, dtype=torch.float32)\n",
        "        wsum = 0.0\n",
        "        for logits in _att[\"logits_list\"]:\n",
        "            sa = torch.sigmoid(logits)[0,0]  # [h,w]\n",
        "            h, w = int(sa.shape[-2]), int(sa.shape[-1])\n",
        "            sa_up = F.interpolate(sa[None,None], size=(H,W), mode=\"bilinear\", align_corners=False)[0,0]\n",
        "            weight = float(h*w)\n",
        "            fused += weight * sa_up\n",
        "            wsum  += weight\n",
        "        fused = fused / (wsum + 1e-6)\n",
        "        fused = fused.masked_fill(torch.from_numpy(pad_mask).to(device), 0.0)\n",
        "        att01 = fused.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "        vals = att01[nonpad_mask]\n",
        "        lo = np.quantile(vals, 0.05)\n",
        "        hi = np.quantile(vals, 0.95)\n",
        "        att01 = np.clip((att01 - lo) / (hi - lo + 1e-6), 0.0, 1.0).astype(np.float32)\n",
        "        att01[pad_mask] = 0.0\n",
        "\n",
        "\n",
        "        # segmentation clean\n",
        "        pred_clean = (torch.sigmoid(seg_logits)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "        iou_clean = iou_bin(pred_clean, gt_mask)\n",
        "\n",
        "\n",
        "      # masks (fixed-size patches)\n",
        "        top_pix = make_top_mask(att01, nonpad_mask, TOP_P)   # TOP_P is fine (0.30)\n",
        "\n",
        "        ys, xs = np.where(top_pix)\n",
        "        if len(ys) == 0:\n",
        "            continue\n",
        "        cy = int(np.mean(ys))\n",
        "        cx = int(np.mean(xs))\n",
        "\n",
        "        top_mask = patch_mask_from_center(nonpad_mask, cy, cx, PATCH_H, PATCH_W)\n",
        "\n",
        "\n",
        "        rand_mask = random_patch_mask(nonpad_mask, PATCH_H, PATCH_W)\n",
        "        if rand_mask is None:\n",
        "            continue\n",
        "\n",
        "\n",
        "        # perturbed inputs\n",
        "        x_top,  img_top_np  = apply_mask_to_x_from_img(x, img_np, top_mask)\n",
        "        x_rand, img_rand_np = apply_mask_to_x_from_img(x, img_np, rand_mask)\n",
        "\n",
        "\n",
        "\n",
        "        # forwards perturbed\n",
        "        _, seg_top,  tag_top  = model(x_top)\n",
        "        _, seg_rand, tag_rand = model(x_rand)\n",
        "\n",
        "        p_top,  pred_top_dn  = tag_prob_night_and_pred(tag_top)\n",
        "        p_rand, pred_rand_dn = tag_prob_night_and_pred(tag_rand)\n",
        "\n",
        "        tag_ok_top.append(int(pred_top_dn == gt_dn))\n",
        "        tag_ok_rand.append(int(pred_rand_dn == gt_dn))\n",
        "\n",
        "        tag_pok_top.append(prob_of_correct_class(p_top, gt_dn))\n",
        "        tag_pok_rand.append(prob_of_correct_class(p_rand, gt_dn))\n",
        "\n",
        "\n",
        "\n",
        "        pred_det_top  = det_predict_boxes(det_eval, img_top_np,  conf=0.25, iou=0.6)\n",
        "        pred_det_rand = det_predict_boxes(det_eval, img_rand_np, conf=0.25, iou=0.6)\n",
        "\n",
        "        ap_top  = ap50_single_image(pred_det_top,  gt_boxes, iou_thr=0.50)\n",
        "        ap_rand = ap50_single_image(pred_det_rand, gt_boxes, iou_thr=0.50)\n",
        "\n",
        "        ap_drops_top.append(ap_clean - ap_top)\n",
        "        ap_drops_rand.append(ap_clean - ap_rand)\n",
        "\n",
        "\n",
        "\n",
        "        pred_top  = (torch.sigmoid(seg_top)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "        pred_rand = (torch.sigmoid(seg_rand)[0,0] > 0.5).detach().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        iou_top  = iou_bin(pred_top, gt_mask)\n",
        "        iou_rand = iou_bin(pred_rand, gt_mask)\n",
        "\n",
        "        drops_top.append(iou_clean - iou_top)\n",
        "        drops_rand.append(iou_clean - iou_rand)\n",
        "\n",
        "# cleanup hooks\n",
        "for h in handles:\n",
        "    h.remove()\n",
        "\n",
        "print(\"Images used:\", len(drops_top))\n",
        "print(\"Mean IoU drop (top-att):\", float(np.mean(drops_top)) if drops_top else None)\n",
        "print(\"Mean IoU drop (random):\",  float(np.mean(drops_rand)) if drops_rand else None)\n",
        "print(\"Mean AP50 drop (top-att):\",  float(np.mean(ap_drops_top)) if ap_drops_top else None)\n",
        "print(\"Mean AP50 drop (random):\",   float(np.mean(ap_drops_rand)) if ap_drops_rand else None)\n",
        "\n",
        "def mean(x):\n",
        "    return float(np.mean(x)) if len(x) else None\n",
        "\n",
        "acc_clean = mean(tag_ok_clean)\n",
        "acc_top   = mean(tag_ok_top)\n",
        "acc_rand  = mean(tag_ok_rand)\n",
        "\n",
        "print(\"Tag Acc clean:\", acc_clean)\n",
        "print(\"Tag Acc top:  \", acc_top,  \"  drop:\", (acc_clean - acc_top) if acc_clean is not None else None)\n",
        "print(\"Tag Acc rand: \", acc_rand, \"  drop:\", (acc_clean - acc_rand) if acc_clean is not None else None)\n",
        "\n",
        "pok_clean = mean(tag_pok_clean)\n",
        "pok_top   = mean(tag_pok_top)\n",
        "pok_rand  = mean(tag_pok_rand)\n",
        "\n",
        "print(\"Tag P(correct) clean:\", pok_clean)\n",
        "print(\"Tag P(correct) top:  \", pok_top,  \"  drop:\", (pok_clean - pok_top) if pok_clean is not None else None)\n",
        "print(\"Tag P(correct) rand: \", pok_rand, \"  drop:\", (pok_clean - pok_rand) if pok_clean is not None else None)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFc-ET48C7Av",
        "outputId": "0917b150-0235-4fae-b7f8-85d322178c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
            "Images used: 1000\n",
            "Mean IoU drop (top-att): 0.16929898551437883\n",
            "Mean IoU drop (random): 0.09067801369320716\n",
            "Mean AP50 drop (top-att): 0.019582364522153513\n",
            "Mean AP50 drop (random): 0.009320265210873913\n",
            "Tag Acc clean: 0.908\n",
            "Tag Acc top:   0.87   drop: 0.038000000000000034\n",
            "Tag Acc rand:  0.876   drop: 0.03200000000000003\n",
            "Tag P(correct) clean: 0.7318826522640884\n",
            "Tag P(correct) top:   0.7159924722909927   drop: 0.01589017997309572\n",
            "Tag P(correct) rand:  0.7138034129329026   drop: 0.018079239331185826\n"
          ]
        }
      ]
    }
  ]
}