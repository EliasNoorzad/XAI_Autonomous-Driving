{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvIGL9kRm0LeNBTyHT6TBB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliasNoorzad/XAI_Autonomous-Driving/blob/main/evaluation/02_baseline_det_seg_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2y8qqiQC-3K",
        "outputId": "3be93983-971d-4acb-c1f1-b593c600f4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics==8.4.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A_0tjABFyuG",
        "outputId": "fc69649b-2a8f-471a-b433-04f275e20963"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/XAI_Project/BDD100K_640.zip /content/\n"
      ],
      "metadata": {
        "id": "f9WCNHCEFywe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/BDD100K_640.zip -d /content/BDD100K_640"
      ],
      "metadata": {
        "id": "simgEgdFFyzA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml = \"\"\"\\\n",
        "path: /content/BDD100K_640/yolo_640\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "nc: 5\n",
        "names: [car, truck, bus, person, bike]\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/BDD100K_640/yolo_640/dataset_640.yaml\", \"w\") as f:\n",
        "    f.write(yaml)\n"
      ],
      "metadata": {
        "id": "aKybJYBEGJrS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class BDDDetDrivableDataset(Dataset):\n",
        "    \"\"\"\n",
        "    For preprocessed 640 dataset (yolo_640 + drivable_masks_640):\n",
        "      images: <yolo_root>/<split>/images/<stem>.jpg\n",
        "      labels: <yolo_root>/<split>/labels/<stem>.txt\n",
        "      masks : <mask_root>/<split>/<stem>.png\n",
        "\n",
        "    Returns:\n",
        "      img   : FloatTensor [3, H, W] in [0,1]\n",
        "      labels: FloatTensor [N, 5] where each row is [cls, x, y, w, h] (YOLO normalized)\n",
        "      mask  : FloatTensor [1, H, W] with values 0/1\n",
        "    \"\"\"\n",
        "    def __init__(self, yolo_root: str, mask_root: str, split: str, imgsz: int = 640):\n",
        "        self.yolo_root = Path(yolo_root)\n",
        "        self.mask_root = Path(mask_root)\n",
        "        self.split = split\n",
        "        self.imgsz = int(imgsz)\n",
        "\n",
        "        self.img_dir = self.yolo_root / split / \"images\"\n",
        "        self.lbl_dir = self.yolo_root / split / \"labels\"\n",
        "        self.msk_dir = self.mask_root / split\n",
        "\n",
        "        if not self.img_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing images dir: {self.img_dir}\")\n",
        "        if not self.lbl_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing labels dir: {self.lbl_dir}\")\n",
        "        if not self.msk_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing masks dir:  {self.msk_dir}\")\n",
        "\n",
        "        exts = {\".jpg\", \".jpeg\", \".png\"}\n",
        "        self.img_paths = sorted([p for p in self.img_dir.iterdir() if p.suffix.lower() in exts])\n",
        "        if len(self.img_paths) == 0:\n",
        "            raise FileNotFoundError(f\"No images found in: {self.img_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    @staticmethod\n",
        "    def _read_yolo_labels(label_path: Path) -> torch.Tensor:\n",
        "        # YOLO txt lines: class x y w h\n",
        "        if not label_path.exists():\n",
        "            return torch.zeros((0, 5), dtype=torch.float32)\n",
        "\n",
        "        rows = []\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                parts = line.split()\n",
        "                if len(parts) != 5:\n",
        "                    continue\n",
        "                cls, x, y, w, h = parts\n",
        "                rows.append([float(cls), float(x), float(y), float(w), float(h)])\n",
        "\n",
        "        if len(rows) == 0:\n",
        "            return torch.zeros((0, 5), dtype=torch.float32)\n",
        "        return torch.tensor(rows, dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def _pil_to_chw_float(img: Image.Image) -> torch.Tensor:\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0  # HWC\n",
        "        arr = np.transpose(arr, (2, 0, 1))  # CHW\n",
        "        return torch.from_numpy(arr)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        img_path = self.img_paths[idx]\n",
        "        stem = img_path.stem\n",
        "\n",
        "        label_path = self.lbl_dir / f\"{stem}.txt\"\n",
        "        mask_path = self.msk_dir / f\"{stem}.png\"\n",
        "\n",
        "        if not mask_path.exists():\n",
        "            raise FileNotFoundError(f\"Missing mask for {stem}: {mask_path}\")\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        # labels are already corrected for 640x640\n",
        "        labels = self._read_yolo_labels(label_path)\n",
        "\n",
        "        # optional safety check (won't change anything if already 640)\n",
        "        if img.size != (self.imgsz, self.imgsz):\n",
        "            img = img.resize((self.imgsz, self.imgsz), resample=Image.BILINEAR)\n",
        "        if mask.size != (self.imgsz, self.imgsz):\n",
        "            mask = mask.resize((self.imgsz, self.imgsz), resample=Image.NEAREST)\n",
        "\n",
        "        img_t = self._pil_to_chw_float(img)  # [3,H,W]\n",
        "        mask_np = (np.array(mask, dtype=np.uint8) > 0).astype(np.float32)\n",
        "        mask_t = torch.from_numpy(mask_np)[None, :, :]  # [1,H,W]\n",
        "\n",
        "        return img_t, labels, mask_t\n"
      ],
      "metadata": {
        "id": "0rlSUXEuOCuv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# IMPORTANT: make sure this imports your LOCAL ultralytics repo, not the installed package.\n",
        "# Example (do this BEFORE importing ultralytics):\n",
        "# import sys\n",
        "# sys.path.insert(0, \"/content/your_project/ultralytics\")  # path that contains the \"ultralytics/\" folder\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "class YOLOv8DetSemSeg(nn.Module):\n",
        "    \"\"\"\n",
        "    YOLOv8 detection model + tiny semantic seg head.\n",
        "    Captures NECK features by hooking the Detect head INPUT (multi-scale features).\n",
        "    \"\"\"\n",
        "    def __init__(self, yolo_weights: str = \"yolov8n.pt\"):\n",
        "        super().__init__()\n",
        "        self.yolo = YOLO(yolo_weights).model  # nn.Module\n",
        "        self._neck_feats = None\n",
        "\n",
        "        self.sem_head = nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self._register_detect_input_hook()\n",
        "\n",
        "    def _register_detect_input_hook(self):\n",
        "        if not hasattr(self.yolo, \"model\"):\n",
        "            raise RuntimeError(\"Unexpected Ultralytics model: no .model\")\n",
        "\n",
        "        detect_module = self.yolo.model[-1]\n",
        "        name = detect_module.__class__.__name__.lower()\n",
        "        if \"detect\" not in name:\n",
        "            raise RuntimeError(f\"Last module is not Detect (got {detect_module.__class__.__name__}).\")\n",
        "\n",
        "        # remove previous hook if exists\n",
        "        if hasattr(self, \"_detect_hook_handle\") and self._detect_hook_handle is not None:\n",
        "            self._detect_hook_handle.remove()\n",
        "\n",
        "        def pre_hook(module, inputs):\n",
        "            self._neck_feats = inputs[0]\n",
        "\n",
        "        self._detect_hook_handle = detect_module.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _pick_high_res_from_detect_inputs(feats):\n",
        "        # feats: list/tuple of [B,C,H,W]\n",
        "        if not isinstance(feats, (list, tuple)) or len(feats) == 0:\n",
        "            raise RuntimeError(\"Detect input features not captured.\")\n",
        "        return max(feats, key=lambda t: t.shape[-2] * t.shape[-1])  # highest H*W (usually P3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # TRAIN: x is a batch dict -> YOLO returns (det_loss, loss_items)\n",
        "      if isinstance(x, dict):\n",
        "          self._neck_feats = None\n",
        "          imgs = x[\"img\"]\n",
        "          det_loss, det_items = self.yolo(x)\n",
        "\n",
        "          feat = self._pick_high_res_from_detect_inputs(self._neck_feats)\n",
        "          seg_logits = self.sem_head(feat)\n",
        "          seg_logits = F.interpolate(seg_logits, size=imgs.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "          return det_loss, det_items, seg_logits\n",
        "\n",
        "      # INFER: x is an image tensor -> YOLO returns preds\n",
        "      self._neck_feats = None\n",
        "      det_preds = self.yolo(x)\n",
        "\n",
        "      feat = self._pick_high_res_from_detect_inputs(self._neck_feats)\n",
        "      seg_logits = self.sem_head(feat)\n",
        "      seg_logits = F.interpolate(seg_logits, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "      return det_preds, seg_logits\n"
      ],
      "metadata": {
        "id": "ITZxKbCpNvYp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_det_seg(batch):\n",
        "    imgs, labels_list, masks = zip(*batch)\n",
        "    imgs = torch.stack(imgs, 0)\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    bboxes_all, cls_all, batch_idx_all = [], [], []\n",
        "    for i, lab in enumerate(labels_list):\n",
        "        if lab.numel() == 0:\n",
        "            continue\n",
        "        cls = lab[:, 0:1].long()     # FIX\n",
        "        bboxes = lab[:, 1:5].float() # keep float\n",
        "        bboxes_all.append(bboxes)\n",
        "        cls_all.append(cls)\n",
        "        batch_idx_all.append(torch.full((lab.shape[0],), i, dtype=torch.long))\n",
        "\n",
        "    if len(bboxes_all):\n",
        "        bboxes = torch.cat(bboxes_all, 0)\n",
        "        cls = torch.cat(cls_all, 0)\n",
        "        batch_idx = torch.cat(batch_idx_all, 0)\n",
        "    else:\n",
        "        bboxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "        cls = torch.zeros((0, 1), dtype=torch.long)   # FIX\n",
        "        batch_idx = torch.zeros((0,), dtype=torch.long)\n",
        "\n",
        "    return {\"img\": imgs, \"bboxes\": bboxes, \"cls\": cls, \"batch_idx\": batch_idx, \"mask\": masks}"
      ],
      "metadata": {
        "id": "4Gf-VRH5OtuY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 1) create wrapper\n",
        "model = YOLOv8DetSemSeg(\n",
        "    yolo_weights=\"/content/drive/MyDrive/XAI_Project/experiments/det_baseline/weights/best_fixednames.pt\"\n",
        ").to(device)\n",
        "\n",
        "# 2) load your det+seg checkpoint (works whether best.pt is a state_dict or a ckpt dict)\n",
        "ckpt = torch.load(\"/content/drive/MyDrive/XAI_Project/experiments/det_seg_noatt_640/weights/best.pt\", map_location=\"cpu\")\n",
        "state = ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else (ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt)\n",
        "model.load_state_dict(state, strict=False)\n",
        "\n",
        "model.eval()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEiNolqvRKLY",
        "outputId": "e658d57f-9f47-4095-dd52-a71229a53fc3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YOLOv8DetSemSeg(\n",
              "  (yolo): DetectionModel(\n",
              "    (model): Sequential(\n",
              "      (0): Conv(\n",
              "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (2): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Conv(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (4): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Conv(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (6): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Conv(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (8): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SPPF(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (11): Concat()\n",
              "      (12): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (14): Concat()\n",
              "      (15): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): Conv(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (17): Concat()\n",
              "      (18): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (19): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (20): Concat()\n",
              "      (21): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (22): Detect(\n",
              "        (cv2): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (cv3): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (dfl): DFL(\n",
              "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (sem_head): Sequential(\n",
              "    (0): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def val_iou(model, loader, device, max_batches=None):\n",
        "    model.eval()\n",
        "    total_iou = 0.0\n",
        "    total_imgs = 0\n",
        "\n",
        "    for bi, batch in enumerate(loader):\n",
        "        if (max_batches is not None) and (bi >= max_batches):\n",
        "            break\n",
        "\n",
        "        img = batch[\"img\"].to(device)\n",
        "        gt  = (batch[\"mask\"].to(device) > 0.5).float()\n",
        "\n",
        "        _, seg_logits = model(img)\n",
        "        pred = (torch.sigmoid(seg_logits) > 0.5).float()\n",
        "\n",
        "        inter = (pred * gt).sum(dim=(1, 2, 3))\n",
        "        union = ((pred + gt) > 0).float().sum(dim=(1, 2, 3)).clamp_min(1.0)\n",
        "\n",
        "        iou = (inter / union)  # [B]\n",
        "        total_iou += iou.sum().item()\n",
        "        total_imgs += iou.numel()\n",
        "\n",
        "    return total_iou / max(1, total_imgs)\n"
      ],
      "metadata": {
        "id": "bBTDYpijPQ15"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = BDDDetDrivableDataset(\n",
        "    yolo_root=\"/content/BDD100K_640/yolo_640\",\n",
        "    mask_root=\"/content/BDD100K_640/drivable_masks_640\",\n",
        "    split=\"test\",\n",
        "    imgsz=640\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=False,\n",
        "    collate_fn=collate_det_seg\n",
        ")\n"
      ],
      "metadata": {
        "id": "e6tIq0LhOdFu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 1) build the wrapper (any YOLO weights just to initialize)\n",
        "model = YOLOv8DetSemSeg(\n",
        "    yolo_weights=\"/content/drive/MyDrive/XAI_Project/experiments/det_baseline/weights/best_fixednames.pt\"\n",
        ").to(device)\n",
        "\n",
        "# 2) load det+seg checkpoint (overwrites everything)\n",
        "sd = torch.load(\"/content/drive/MyDrive/XAI_Project/experiments/det_seg_noatt_640/weights/best.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(sd, strict=True)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "wzD_ef5BQFVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "BASE = YOLO(\"/content/drive/MyDrive/XAI_Project/experiments/det_baseline/weights/best_fixednames.pt\")\n",
        "m_base = BASE.val(data=\"/content/BDD100K_640/yolo_640/dataset_640.yaml\", imgsz=640, device=0, split=\"test\")\n",
        "print(\"BASE mAP50 =\", m_base.box.map50, \"mAP50-95 =\", m_base.box.map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdj3pRFGGQWv",
        "outputId": "c3c032da-3436-4b22-cd68-34e86e8fefd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.6 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 32.6Â±17.5 MB/s, size: 69.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/BDD100K_640/yolo_640/test/labels... 20000 images, 143 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20000/20000 627.6it/s 31.9s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/BDD100K_640/yolo_640/test/images/e6f10c58-c46de527.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/BDD100K_640/yolo_640/test/labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1250/1250 6.6it/s 3:09\n",
            "                   all      20000     243649      0.646      0.478      0.531      0.328\n",
            "                   car      19776     205093      0.747      0.687      0.744      0.458\n",
            "                 truck       5500       8701      0.657       0.49      0.561      0.403\n",
            "                   bus       2459       3217      0.624      0.446      0.506      0.385\n",
            "                person       6213      24641      0.663      0.455      0.521      0.249\n",
            "                  bike       1182       1997      0.537      0.312      0.325      0.148\n",
            "Speed: 1.0ms preprocess, 3.5ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val4\u001b[0m\n",
            "BASE mAP50 = 0.5314979327473413 mAP50-95 = 0.328429419210122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "sd = torch.load(\"/content/drive/MyDrive/XAI_Project/experiments/det_seg_noatt_640/weights/best.pt\", map_location=\"cpu\")\n",
        "\n",
        "y = YOLO(\"/content/drive/MyDrive/XAI_Project/experiments/det_baseline/weights/best_fixednames.pt\")\n",
        "yolo_sd = {k.replace(\"yolo.\", \"\"): v for k, v in sd.items() if k.startswith(\"yolo.\")}\n",
        "y.model.load_state_dict(yolo_sd, strict=True)\n",
        "\n",
        "m_new = y.val(data=\"/content/BDD100K_640/yolo_640/dataset_640.yaml\", imgsz=640, device=0, split=\"test\")\n",
        "print(\"NEW  mAP50 =\", m_new.box.map50, \"mAP50-95 =\", m_new.box.map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i89pcGoFGVBm",
        "outputId": "da33350d-be8f-4b2a-d1b8-d85c3ff1f546"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.6 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1339.0Â±503.2 MB/s, size: 66.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/BDD100K_640/yolo_640/test/labels.cache... 20000 images, 143 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20000/20000 5.6Git/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/BDD100K_640/yolo_640/test/images/e6f10c58-c46de527.jpg: 1 duplicate labels removed\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1250/1250 6.7it/s 3:07\n",
            "                   all      20000     243649      0.625      0.467      0.507      0.303\n",
            "                   car      19776     205093       0.78       0.66      0.739      0.444\n",
            "                 truck       5500       8701      0.586      0.496      0.522      0.362\n",
            "                   bus       2459       3217       0.62      0.423      0.465      0.335\n",
            "                person       6213      24641      0.689      0.427      0.508       0.24\n",
            "                  bike       1182       1997      0.448      0.326      0.304      0.134\n",
            "Speed: 1.0ms preprocess, 3.5ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val5\u001b[0m\n",
            "NEW  mAP50 = 0.5074095333818496 mAP50-95 = 0.3032004531283928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "best_pt = \"/content/drive/MyDrive/XAI_Project/experiments/det_seg_noatt_640/weights/best.pt\"\n",
        "sd = torch.load(best_pt, map_location=\"cpu\")\n",
        "\n",
        "model.load_state_dict(sd, strict=True)\n",
        "model.to(device).eval()\n",
        "\n",
        "iou_full = val_iou(model, test_loader, device, max_batches=None)\n",
        "print(\"test_iou_full =\", iou_full)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldqlnRHyNQDJ",
        "outputId": "fada6268-ffa6-4277-c251-7849b1a48b6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_iou_full = 0.6641148620903492\n"
          ]
        }
      ]
    }
  ]
}